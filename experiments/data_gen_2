#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Sep 23 15:48:03 2019

@author: harshparikh
"""
import numpy as np
import scipy
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
import scipy.stats as stats

np.random.seed(0)

def roll(bias_list):
    number = np.random.uniform(0, sum(bias_list))
    current = 0
    for i, bias in enumerate(bias_list):
        current += bias
        if number <= current:
            return i

## Generate Authors
def gen_inst(n_inst):
    def gen():
        inst_prestige = np.random.exponential(10)
        return [inst_prestige]
    d_inst = {}
    for i in range(0,n_inst):
        d_insti = {}
        inst = gen()
        d_insti['prestige'] = inst[0]
        d_inst[i] = d_insti
    d_inst = pd.DataFrame.from_dict(d_inst,orient='index')
    return d_inst

def gen_author(n_auth,df_inst):
    def gen():
        x = np.random.binomial(1,1/3)*np.random.exponential(0.75) + np.random.binomial(1,1/2)*np.random.normal(20,4) + np.random.binomial(1,1/4)*np.random.normal(35,1)
        experience = max(0,x)+1 #experience is normally distributed but always positive
        gender = np.random.binomial(1,1/2) #gender 0: male or 1: female
        w = [np.random.binomial(1,1/2), np.random.binomial(1,1/3), np.random.binomial(1,1/5), np.random.binomial(1,1/16)]
        x = [np.random.poisson(100), np.random.poisson(200), np.random.poisson(500), np.random.poisson(1000)]
        citation = int(np.dot(w,x)*experience/30)+1 #citation count as generated using multimodal poisson distribution
        expertise = np.random.randint(0,10) #field of expertise
        high = np.array(df_inst['prestige']) #prestige of each school
        low = 10/high #inverse of prestige of school normalized by 10
        inv_cit = 304.166/(citation+1) #inverse of citation count times a normalizing factor
        affiliation_prob = scipy.special.expit(0.1*high*citation + 0.1*low*inv_cit - 0.1*high*inv_cit - 0.1*low*citation) #prob((a,i)) is \prop I[high]A[high] + I[low]A[low] - I[high]A[low] - I[low]A[high]
        affiliation_prob = affiliation_prob*(30/(experience+1))/sum(affiliation_prob*(30/(experience+1))) #normalizing
        auth_inst_id = roll(affiliation_prob) #rolling a biased dice
        return [gender,experience,citation,expertise,auth_inst_id]
    d_auth = {}
    for i in range(0,n_auth):
        d_authi = {}
        auth = gen()
        d_authi['age'] = auth[0]
        d_authi['experience'] = auth[1]
        d_authi['citation'] = auth[2]
        d_authi['expertise'] = auth[3]
        d_authi['affiliation'] = auth[4]
        d_auth[i] = d_authi
    return pd.DataFrame.from_dict(d_auth,orient='index')

def gen_conf(n_conf):
    def gen():
        impact_fac = np.random.exponential(10)
        area = np.random.randint(0,10)
        blind = np.random.binomial(1,2/3)
        return [area,impact_fac,blind]
    d_conf = {}
    for i in range(n_conf):
        d_confi = {}
        conf = gen()
        d_confi['area'] = conf[0]
        d_confi['impact_factor'] = conf[1]
        d_confi['single-blind'] = conf[2]
        d_conf[i] = d_confi
    return pd.DataFrame.from_dict(d_conf,orient='index')

def gen_paper(n_paper,df_conf,df_auth,df_inst):
    def gen():
        num_auth = int(np.random.exponential(2.5) + 1)
        authors = np.random.choice(len(df_auth), size = num_auth, replace=False) #randomly choose K authors, can be made more meaningful
        quality = scipy.special.expit(np.sum([ (np.e**(-2*i))*np.log(30*(df_auth.loc[authors[i]]['citation']/(df_auth.loc[authors[i]]['experience']+5))+1) for i in range(num_auth) ])/5 - 1)#*((np.random.normal(20,5) + stats.mode([ df_auth.loc[authors[i]]['experience'] for i in range(num_auth) ])[0][0]**2)/500)#+ 0.5(np.mode())
        paper_conf = np.random.randint(0,len(df_conf)) #randomly apply to any conference, could be made better
        collapsed_prestige = np.percentile( np.array([ df_inst.loc[df_auth.loc[a]['affiliation']]['prestige'] for a in authors] ), 75 )#collective prestige of all authors
        isolated = df_conf.loc[paper_conf]['single-blind']*(collapsed_prestige>10)
        relational = 0
        review_score = max( 0, min( 10, 3+isolated+( 10*np.random.normal(np.log(quality+1) - np.log(df_conf.loc[paper_conf]['impact_factor'])/10,0.1*quality))/1.5)) #max(0,min(20,(df_conf.loc[paper_conf]['single-blind'])*(median_prestige>10) + (80*quality)/(df_conf.loc[paper_conf]['impact_factor']))) #if it is single-blind then the treatment effect of median-prestige=high is 1.
        return [authors,quality,paper_conf,review_score]
    d_paper = {}
    for i in range(0,n_paper):
        d_paperi = {}
        paper = gen()
        d_paperi['authors'] = paper[0]
        d_paperi['quality'] = paper[1]
        d_paperi['venue'] = paper[2]
        d_paperi['review'] = paper[3]
        d_paper[i] = d_paperi
    return pd.DataFrame.from_dict(d_paper,orient='index')
        
    
def generate_data(n_auth,n_inst,n_paper,n_conf):
    #generating fundamental entities
    df_inst = gen_inst(n_inst)
    df_auth = gen_author(n_auth,df_inst)
    df_conf = gen_conf(n_conf)
    df_paper = gen_paper(n_paper,df_conf,df_auth,df_inst)
    
    #making coauthor network
    coauthors = {a:set() for a in range(0,len(df_auth))}
    for p in range(0,len(df_paper)):
        p_auth = df_paper.loc[p]['authors']
        for at in p_auth:
            coauthors[at] = coauthors[at].union(set(p_auth)-set([at]))
    df_coauthors = pd.DataFrame.from_dict(coauthors,orient='index',columns='coauthor_set')
    
    #calculating relational effect and adding to the main papers table
    for p in range(0,len(df_paper)):
        p_auth = df_paper.loc[p]['authors']
        coauth = set()
        for at in p_auth:
            coauth = coauth.union(df_coauthors.loc[at]['coauthor_set'])
        coauth = coauth-set(p_auth)
        ca_prestige_vec = [ df_inst.loc[df_auth.loc[ca]['affiliation']]['prestige'] for ca in coauth ]
        relce_p = 0.5*(np.mean(ca_prestige_vec)>10)
        df_paper.loc[p,'review'] = df_paper.loc[p,'review'] + relce_p
    df = {'institutes': df_inst, 'authors': df_auth, 'conferences': df_conf, 'papers': df_paper, 'coauthors': df_coauthors}
    return df
